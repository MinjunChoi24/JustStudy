from scraper import get_news_data
from classifier import analyze_article
from uploader import save_to_notion

def main():
    print("ğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ ê°€ë™!")
    
    # 1. ë‰´ìŠ¤ ìˆ˜ì§‘ 
    print("\n[1ë‹¨ê³„] ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸ì–´ì˜¤ëŠ” ì¤‘...")
    
    news_list = get_news_data()
    
    print(f"--> ì´ {len(news_list)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    # 2. í•˜ë‚˜ì”© AI ë¶„ì„ í›„ ë…¸ì…˜ ì €ì¥
    print("\n[2ë‹¨ê³„] AI ë¶„ì„ ë° ë…¸ì…˜ ì €ì¥ ì‹œì‘...")
    

    for i, news in enumerate(news_list):
        print(f"\n[{i+1}/{len(news_list)}] ì²˜ë¦¬ ì¤‘: {news['Title']}...")
        
        # AI ë¶„ì„
        ai_result = analyze_article(news)
        
        # ê²°ê³¼ ì¶œë ¥ (í™•ì¸ìš©)
        print(f"   ã„´ ë¶„ë¥˜: {ai_result.get('Category')} | ì£¼ì œ: {ai_result.get('Subject')} | {ai_result.get('Sector')}")
        
        # ë…¸ì…˜ ì €ì¥
        save_to_notion(news, ai_result)

    print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ë…¸ì…˜ì„ í™•ì¸í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()